{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bone Fracture Detection V2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abntrPUaqw3u",
        "outputId": "1fa57803-e208-40b9-d231-3b48e42a7db2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Bone Fracture Detection\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"/content/drive/My Drive/MURA-v1.1.zip\"\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print(\"Completed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9soIvCc_rBTt",
        "outputId": "0e7e52ad-fbbd-460c-f8d3-5fa0def72787"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
        "from keras.preprocessing.image import * #image\n",
        "from keras import regularizers\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.applications.densenet import DenseNet169, DenseNet121, preprocess_input\n",
        "from time import time\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import datetime"
      ],
      "metadata": {
        "id": "rqrFOecPrTIA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install focal-loss\n",
        "!pip install keras-radam"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B70kMigftSrI",
        "outputId": "4de442dd-f449-4d0e-b635-d221b6f00f19"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting focal-loss\n",
            "  Downloading focal_loss-0.0.7-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: tensorflow>=2.2 in /usr/local/lib/python3.7/dist-packages (from focal-loss) (2.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (3.10.0.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (12.0.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.7.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.13.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.1.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (3.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.6.3)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.19.5)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (0.37.1)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.7.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (0.12.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (0.23.1)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.1.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.43.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.2->focal-loss) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2->focal-loss) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2->focal-loss) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2->focal-loss) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2->focal-loss) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2->focal-loss) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2->focal-loss) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2->focal-loss) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2->focal-loss) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.2->focal-loss) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.2->focal-loss) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.2->focal-loss) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.2->focal-loss) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.2->focal-loss) (4.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.2->focal-loss) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.2->focal-loss) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.2->focal-loss) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.2->focal-loss) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.2->focal-loss) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.2->focal-loss) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.2->focal-loss) (3.1.1)\n",
            "Installing collected packages: focal-loss\n",
            "Successfully installed focal-loss-0.0.7\n",
            "Collecting keras-radam\n",
            "  Downloading keras-radam-0.15.0.tar.gz (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-radam) (1.19.5)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (from keras-radam) (2.7.0)\n",
            "Building wheels for collected packages: keras-radam\n",
            "  Building wheel for keras-radam (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-radam: filename=keras_radam-0.15.0-py3-none-any.whl size=14686 sha256=3825fa784b1c973baa88d8e89fd2499f7efbbd7751700198382eca7d367d2ece\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/6a/5f/d674f3b7b4d504b03148abd675e3703ba00c31763c04a2fc20\n",
            "Successfully built keras-radam\n",
            "Installing collected packages: keras-radam\n",
            "Successfully installed keras-radam-0.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from focal_loss import BinaryFocalLoss\n",
        "from keras_radam import RAdam\n"
      ],
      "metadata": {
        "id": "5UzHFeCatZ18"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def listdir_nohidden(path):\n",
        "    '''\n",
        "    Utility function to find the list of files in a directory excluding the hidden files.\n",
        "    Args:\n",
        "        path: contains the path of the directory containing the images\n",
        "\n",
        "    '''\n",
        "    for f in os.listdir(path):\n",
        "        if not f.startswith('.'):\n",
        "            yield f\n",
        "# this will basically ingnore hidden files"
      ],
      "metadata": {
        "id": "YsBb39OwtdgC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_images_metadata_csv(category,study_types):\n",
        "    '''\n",
        "    This function creates a csv file containing the path of images, label.\n",
        "    Args:\n",
        "        category: train or valid, depending on which csv is needed\n",
        "        study_types: the type of the body part in MURA Dataset, eg:  XR_SHOULDER\n",
        "    '''\n",
        "    image_data = {}\n",
        "    study_label = {'positive': 1, 'negative': 0}\n",
        "    #study_types = ['XR_ELBOW','XR_FINGER','XR_FOREARM','XR_HAND','XR_HUMERUS','XR_SHOULDER','XR_WRIST']\n",
        "    #study_types = ['XR_ELBOW']\n",
        "    i = 0\n",
        "    image_data[category] = pd.DataFrame(columns=['Path','Count', 'Label'])\n",
        "    for study_type in study_types: # Iterate throught every study types\n",
        "        DATA_DIR = 'MURA-v1.1/%s/%s/' % (category, study_type)\n",
        "        patients = list(os.walk(DATA_DIR))[0][1]  # list of patient folder names\n",
        "        for patient in tqdm(patients):  # for each patient folder\n",
        "            for study in os.listdir(DATA_DIR + patient):  # for each study in that patient folder\n",
        "                if(study != '.DS_Store'):\n",
        "                    label = study_label[study.split('_')[1]]  # get label 0 or 1\n",
        "                    path = DATA_DIR + patient + '/' + study + '/'  # path to this study\n",
        "                    for j in range(len(list(listdir_nohidden(path)))):\n",
        "                        image_path = path + 'image%s.png' % (j + 1)\n",
        "                        image_data[category].loc[i] = [image_path,1, label]  # add new row\n",
        "                        i += 1\n",
        "    image_data[category].to_csv(category+\"_image_data.csv\",index = None, header=False)"
      ],
      "metadata": {
        "id": "u9UtTZ80urT6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getImageLabels(dataframe):\n",
        "  '''\n",
        "  This function is to get the labels of the images from the dataframe\n",
        "  Args:\n",
        "      dataframe: pandas dataframe containing the labels of the images\n",
        "\n",
        "  '''\n",
        "  labels = []\n",
        "  for i, data in tqdm(dataframe.iterrows()):\n",
        "\n",
        "      labels.append(data['Label'])\n",
        "\n",
        "  labels = np.asarray(labels)\n",
        "  return labels"
      ],
      "metadata": {
        "id": "RLIeZQX5vOTn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getImage(dataframe, size):\n",
        "    '''\n",
        "    Function to process the images\n",
        "    Args:\n",
        "        dataframe: contains the path to the images in the directory\n",
        "        size: contains the value to which the shape of the image will resized\n",
        "    '''\n",
        "    Images = []\n",
        "    for i, data in tqdm(dataframe.iterrows()):\n",
        "      try:\n",
        "        image = cv2.imread(data['Path'])#cv2.IMREAD_GRAYSCALE)\n",
        "        image = cv2.resize(image,(size,size))\n",
        "        #image = randome_rotation_flip(image,size)\n",
        "        Images.append(image)\n",
        "\n",
        "      except Exception as e:\n",
        "        print(str(e))\n",
        "\n",
        "    Images = np.asarray(Images).astype('float32')\n",
        "\n",
        "    mean = np.mean(Images)\t\t\t#normalization\n",
        "    std = np.std(Images)\n",
        "    Images = (Images - mean) / std\n",
        "    \n",
        "  \n",
        "    return Images"
      ],
      "metadata": {
        "id": "vhi99qs9vTa9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "    base_model = DenseNet169(input_shape=(None, None,3),\n",
        "                             weights='imagenet',\n",
        "                             include_top=False,\n",
        "                             pooling='avg')\n",
        "\n",
        "\n",
        "    x = base_model.output\n",
        "\n",
        "    predictions = Dense(n_classes,activation='sigmoid')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model"
      ],
      "metadata": {
        "id": "OV_HggPmvZAa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **DATA PROCESSING**"
      ],
      "metadata": {
        "id": "1fOL4BWwOYn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_width, img_height = 224, 224\n",
        "#Keras ImageDataGenerator to load, transform the images of the dataset\n",
        "\n",
        "IMG_DATA_DIR = 'MURA-v1.1/'\n",
        "train_data_dir = IMG_DATA_DIR + 'train/XR_HUMERUS'\n",
        "valid_data_dir = IMG_DATA_DIR + 'valid/XR_HUMERUS'\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    horizontal_flip=True\n",
        "\n",
        ")\n",
        "study_types = ['XR_HUMERUS']\n",
        "\n",
        "#TRAIN DATA\n",
        "create_images_metadata_csv('train',study_types)\n",
        "#VALID DATA\n",
        "create_images_metadata_csv('valid',study_types)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzqifeWhMyJn",
        "outputId": "f58cd5bf-c4f1-4d00-e1c6-d9c24dec65e5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 587/587 [00:04<00:00, 143.39it/s]\n",
            "100%|██████████| 132/132 [00:00<00:00, 161.41it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_image_df = pd.read_csv('valid_image_data.csv', names=['Path','Count', 'Label'])\n",
        "train_image_df = pd.read_csv('train_image_data.csv', names=['Path', 'Count','Label'])\n",
        "\n",
        "dd={}\n",
        "\n",
        "dd['train'] = train_image_df\n",
        "dd['valid'] = valid_image_df"
      ],
      "metadata": {
        "id": "NJc5lmzuOXWl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_image_labels = getImageLabels(train_image_df)\n",
        "train_images = getImage(train_image_df, size = 224)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXsggYkLOv9W",
        "outputId": "130fbb47-3344-46d4-eeb0-1b4e27ba7254"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1272it [00:00, 10696.22it/s]\n",
            "1272it [00:05, 233.03it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape\n",
        "train_datagen.fit(train_images,augment=True)\n",
        "train_generator = train_datagen.flow(\n",
        "    x=train_images,\n",
        "    y=train_image_labels,\n",
        "    batch_size = 32\n",
        ")"
      ],
      "metadata": {
        "id": "ccvEfKVGO4s8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_image_labels = getImageLabels(valid_image_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opAqlQkUPFii",
        "outputId": "24240b54-142c-4982-8d00-a60778ac8197"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "288it [00:00, 12964.56it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_images = getImage(valid_image_df, size = 224)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWOXLUwWPJDF",
        "outputId": "d68294f0-f7f6-4d94-a8e1-c39df423c736"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "288it [00:01, 193.62it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen.fit(valid_images,augment=True)"
      ],
      "metadata": {
        "id": "8tIr0vsKPMup"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_train_samples = len(train_images)\n",
        "nb_validation_samples = len(valid_images)\n",
        "epochs = 12\n",
        "batch_size = 32\n",
        "steps_per_epoch = nb_train_samples//batch_size\n",
        "print(steps_per_epoch)\n",
        "n_classes = 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjYIj5Sj-huU",
        "outputId": "82776e59-3b09-4b17-a2d5-1ca78b67bc70"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Building a model\n",
        "input_shape = (224, 224, 1)\n",
        "model = build_model()\n",
        "\n",
        "model.compile(loss=BinaryFocalLoss(gamma = 2), optimizer='adam', metrics=['acc', 'mse'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfHDmWtzBcEl",
        "outputId": "e11f26ea-e9d7-4e09-fa18-91f17acc9191"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "51879936/51877672 [==============================] - 1s 0us/step\n",
            "51888128/51877672 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#call backs for early stopping incase of reduced learning rate, loss unimprovement\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=8, verbose=1, min_delta=1e-4)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, verbose=1, min_lr=0.0001)\n",
        "callbacks_list = [early_stop, reduce_lr]"
      ],
      "metadata": {
        "id": "st0Yow_9B0Lq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train the module\n",
        "model_history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    workers=0,\n",
        "    use_multiprocessing=False,  \n",
        "    steps_per_epoch = nb_train_samples//batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples //batch_size,\n",
        "    callbacks=callbacks_list\n",
        "    \n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-5SUvdHB8WW",
        "outputId": "a055b448-fa3e-4f03-a514-cf22b03db66c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "39/39 [==============================] - 70s 972ms/step - loss: 0.2666 - acc: 0.5798 - mse: 0.2494 - val_loss: 3.5818 - val_acc: 0.7778 - val_mse: 0.2222 - lr: 0.0010\n",
            "Epoch 2/12\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.1666 - acc: 0.6661 - mse: 0.2218\n",
            "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "39/39 [==============================] - 31s 804ms/step - loss: 0.1666 - acc: 0.6661 - mse: 0.2218 - val_loss: 5.3922 - val_acc: 0.5556 - val_mse: 0.3614 - lr: 0.0010\n",
            "Epoch 3/12\n",
            "39/39 [==============================] - 30s 758ms/step - loss: 0.1399 - acc: 0.7444 - mse: 0.2098 - val_loss: 1.0030 - val_acc: 0.2222 - val_mse: 0.4626 - lr: 1.0000e-04\n",
            "Epoch 4/12\n",
            "39/39 [==============================] - 30s 761ms/step - loss: 0.1325 - acc: 0.7500 - mse: 0.1967 - val_loss: 0.5856 - val_acc: 0.5556 - val_mse: 0.3530 - lr: 1.0000e-04\n",
            "Epoch 5/12\n",
            "39/39 [==============================] - 30s 757ms/step - loss: 0.1231 - acc: 0.7823 - mse: 0.1842 - val_loss: 0.4107 - val_acc: 0.6667 - val_mse: 0.3059 - lr: 1.0000e-04\n",
            "Epoch 6/12\n",
            "39/39 [==============================] - 30s 760ms/step - loss: 0.1236 - acc: 0.7855 - mse: 0.1818 - val_loss: 0.0722 - val_acc: 0.8889 - val_mse: 0.1286 - lr: 1.0000e-04\n",
            "Epoch 7/12\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.1180 - acc: 0.7968 - mse: 0.1739\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "39/39 [==============================] - 30s 761ms/step - loss: 0.1180 - acc: 0.7968 - mse: 0.1739 - val_loss: 0.1098 - val_acc: 0.7778 - val_mse: 0.1610 - lr: 1.0000e-04\n",
            "Epoch 8/12\n",
            "39/39 [==============================] - 30s 775ms/step - loss: 0.1134 - acc: 0.8032 - mse: 0.1703 - val_loss: 0.1818 - val_acc: 0.7778 - val_mse: 0.2107 - lr: 1.0000e-04\n",
            "Epoch 9/12\n",
            "39/39 [==============================] - 30s 769ms/step - loss: 0.1096 - acc: 0.8274 - mse: 0.1617 - val_loss: 0.2111 - val_acc: 0.7778 - val_mse: 0.2195 - lr: 1.0000e-04\n",
            "Epoch 10/12\n",
            "39/39 [==============================] - 30s 761ms/step - loss: 0.1067 - acc: 0.8282 - mse: 0.1572 - val_loss: 0.0934 - val_acc: 0.8889 - val_mse: 0.1480 - lr: 1.0000e-04\n",
            "Epoch 11/12\n",
            "39/39 [==============================] - 30s 757ms/step - loss: 0.0997 - acc: 0.8508 - mse: 0.1514 - val_loss: 0.1046 - val_acc: 0.7778 - val_mse: 0.1646 - lr: 1.0000e-04\n",
            "Epoch 12/12\n",
            "39/39 [==============================] - 30s 757ms/step - loss: 0.1043 - acc: 0.8411 - mse: 0.1523 - val_loss: 0.0626 - val_acc: 0.8889 - val_mse: 0.1229 - lr: 1.0000e-04\n"
          ]
        }
      ]
    }
  ]
}