{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsCwWJj5_dZ6",
        "outputId": "b32dc0a1-1617-49b8-d0f7-58bae997c180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Bone Fracture Detection\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gWhqpQZ_uo_",
        "outputId": "1573b022-3d75-4081-ffd3-ba2ff4fff16f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting focal-loss\n",
            "  Downloading focal_loss-0.0.7-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: tensorflow>=2.2 in /usr/local/lib/python3.7/dist-packages (from focal-loss) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (0.24.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.0.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.6.3)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (0.5.3)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (0.2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (13.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (3.10.0.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.44.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.13.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (57.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.8.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (3.17.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.21.5)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.2->focal-loss) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.2->focal-loss) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (2.23.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.2->focal-loss) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly, focal-loss\n",
            "Successfully installed focal-loss-0.0.7 tf-estimator-nightly-2.8.0.dev2021122109\n",
            "Collecting keras-radam\n",
            "  Downloading keras-radam-0.15.0.tar.gz (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-radam) (1.21.5)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (from keras-radam) (2.8.0)\n",
            "Building wheels for collected packages: keras-radam\n",
            "  Building wheel for keras-radam (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-radam: filename=keras_radam-0.15.0-py3-none-any.whl size=14686 sha256=fddc82afd1d2b1b8c1eab049278da57c52865de7774ea855f8892e8cc87ca9f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/6a/5f/d674f3b7b4d504b03148abd675e3703ba00c31763c04a2fc20\n",
            "Successfully built keras-radam\n",
            "Installing collected packages: keras-radam\n",
            "Successfully installed keras-radam-0.15.0\n"
          ]
        }
      ],
      "source": [
        "!pip install focal-loss\n",
        "!pip install keras-radam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9oIJQacAAZbN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Conv2D, Conv3D, DepthwiseConv2D, SeparableConv2D, Conv3DTranspose\n",
        "from keras.layers import Flatten, MaxPool2D, AvgPool2D, GlobalAvgPool2D, UpSampling2D, BatchNormalization\n",
        "from keras.layers import Concatenate, Add, Dropout, ReLU, Lambda, Activation, LeakyReLU, PReLU\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img#, image\n",
        "from keras import regularizers\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.applications.densenet import DenseNet169, DenseNet121, preprocess_input\n",
        "from time import time\n",
        "\n",
        "\n",
        "from focal_loss import BinaryFocalLoss\n",
        "from keras_radam import RAdam\n",
        "\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECZmFMooAg6O",
        "outputId": "b0378ec9-df96-4d84-cdb2-b04388230914"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed\n"
          ]
        }
      ],
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"/content/drive/My Drive/MURA-v1.1.zip\"\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print(\"Completed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "faI82XbKAlo8"
      },
      "outputs": [],
      "source": [
        "def listdir_nohidden(path):\n",
        "    '''\n",
        "    Utility function to find the list of files in a directory excluding the hidden files.\n",
        "    Args:\n",
        "        path: contains the path of the directory containing the images\n",
        "\n",
        "    '''\n",
        "    for f in os.listdir(path):\n",
        "        if not f.startswith('.'):\n",
        "            yield f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oR4ZApRtA5d9"
      },
      "outputs": [],
      "source": [
        "def create_images_metadata_csv(category,study_types):\n",
        "    '''\n",
        "    This function creates a csv file containing the path of images, label.\n",
        "    Args:\n",
        "        category: train or valid, depending on which csv is needed\n",
        "        study_types: the type of the body part in MURA Dataset, eg:  XR_SHOULDER\n",
        "    '''\n",
        "    image_data = {}\n",
        "    study_label = {'positive': 1, 'negative': 0}\n",
        "    #study_types = ['XR_ELBOW','XR_FINGER','XR_FOREARM','XR_HAND','XR_HUMERUS','XR_SHOULDER','XR_WRIST']\n",
        "    #study_types = ['XR_ELBOW']\n",
        "    i = 0\n",
        "    image_data[category] = pd.DataFrame(columns=['Path','Count', 'Label'])\n",
        "    for study_type in study_types: # Iterate throught every study types\n",
        "        DATA_DIR = 'MURA-v1.1/%s/%s/' % (category, study_type)\n",
        "        patients = list(os.walk(DATA_DIR))[0][1]  # list of patient folder names\n",
        "        for patient in tqdm(patients):  # for each patient folder\n",
        "            for study in os.listdir(DATA_DIR + patient):  # for each study in that patient folder\n",
        "                if(study != '.DS_Store'):\n",
        "                    label = study_label[study.split('_')[1]]  # get label 0 or 1\n",
        "                    path = DATA_DIR + patient + '/' + study + '/'  # path to this study\n",
        "                    for j in range(len(list(listdir_nohidden(path)))):\n",
        "                        image_path = path + 'image%s.png' % (j + 1)\n",
        "                        image_data[category].loc[i] = [image_path,1, label]  # add new row\n",
        "                        i += 1\n",
        "    image_data[category].to_csv(category+\"_image_data.csv\",index = None, header=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wJLIWcBTA9D0"
      },
      "outputs": [],
      "source": [
        "def getImageLabels(dataframe):\n",
        "  '''\n",
        "  This function is to get the labels of the images from the dataframe\n",
        "  Args:\n",
        "      dataframe: pandas dataframe containing the labels of the images\n",
        "\n",
        "  '''\n",
        "  labels = []\n",
        "  for i, data in tqdm(dataframe.iterrows()):\n",
        "#        img = cv2.imread(data['Path'])\n",
        "#         #random rotation\n",
        "#         angle = random.randint(-30,30)\n",
        "#         M = cv2.getRotationMatrix2D((img_width/2,img_height/2),angle,1)\n",
        "#         img = cv2.warpAffine(img,M,(img_width,img_height))\n",
        "      #resize\n",
        "#        img = cv2.resize(img,(img_width,img_height))    \n",
        "#        img = img[...,::-1].astype(np.float32)\n",
        "#        images.append(img)\n",
        "      labels.append(data['Label'])\n",
        "#    images = np.asarray(images).astype('float32') \n",
        "  #normalization\n",
        "#    mean = np.mean(images[:, :, :])\n",
        "#    std = np.std(images[:, :, :])\n",
        "#    images[:, :, :] = (images[:, :, :] - mean) / std\n",
        "  labels = np.asarray(labels)\n",
        "  return labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gFhEzrKEBAzW"
      },
      "outputs": [],
      "source": [
        "def getImage(dataframe, size):\n",
        "    '''\n",
        "    Function to process the images\n",
        "    Args:\n",
        "        dataframe: contains the path to the images in the directory\n",
        "        size: contains the value to which the shape of the image will resized\n",
        "    '''\n",
        "    Images = []\n",
        "    for i, data in tqdm(dataframe.iterrows()):\n",
        "      try:\n",
        "        image = cv2.imread(data['Path'])#cv2.IMREAD_GRAYSCALE)\n",
        "        image = cv2.resize(image,(size,size))\n",
        "        #image = randome_rotation_flip(image,size)\n",
        "        Images.append(image)\n",
        "\n",
        "      except Exception as e:\n",
        "        print(str(e))\n",
        "\n",
        "    Images = np.asarray(Images).astype('float32')\n",
        "\n",
        "    mean = np.mean(Images)\t\t\t#normalization\n",
        "    std = np.std(Images)\n",
        "    Images = (Images - mean) / std\n",
        "    \n",
        "    #if K.image_data_format() == \"channels_first\":\n",
        "    #  Images = np.expand_dims(Images,axis=3)\t\t   #Extended dimension 1\n",
        "    #if K.image_data_format() == \"channels_last\":\n",
        "    #  Images = np.expand_dims(Images,axis=3)             #Extended dimension 3(usebackend tensorflow:aixs=3; theano:axixs=1) \n",
        "    return Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1yo-dg3mBEyz"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "    base_model = DenseNet169(input_shape=(None, None,3),\n",
        "                             weights='imagenet',\n",
        "                             include_top=False,\n",
        "                             pooling='avg')\n",
        "\n",
        "\n",
        "    x = base_model.output\n",
        "\n",
        "    predictions = Dense(n_classes,activation='sigmoid')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmrfZOyvBH6b",
        "outputId": "5eeca165-ef78-4821-9cd5-7bf6c26a43ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 587/587 [00:04<00:00, 146.74it/s]\n",
            "100%|██████████| 132/132 [00:00<00:00, 150.44it/s]\n"
          ]
        }
      ],
      "source": [
        "###################\n",
        "# Data processing #\n",
        "###################\n",
        "\n",
        "img_width, img_height = 224, 224\n",
        "#Keras ImageDataGenerator to load, transform the images of the dataset\n",
        "\n",
        "IMG_DATA_DIR = 'MURA-v1.1/'\n",
        "train_data_dir = IMG_DATA_DIR + 'train/XR_HUMERUS'\n",
        "valid_data_dir = IMG_DATA_DIR + 'valid/XR_HUMERUS'\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    horizontal_flip=True\n",
        "\n",
        ")\n",
        "study_types = ['XR_HUMERUS']\n",
        "\n",
        "#TRAIN DATA\n",
        "create_images_metadata_csv('train',study_types)\n",
        "#VALID DATA\n",
        "create_images_metadata_csv('valid',study_types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "eCrWxGFrBM7n"
      },
      "outputs": [],
      "source": [
        "valid_image_df = pd.read_csv('valid_image_data.csv', names=['Path','Count', 'Label'])\n",
        "train_image_df = pd.read_csv('train_image_data.csv', names=['Path', 'Count','Label'])\n",
        "\n",
        "dd={}\n",
        "\n",
        "dd['train'] = train_image_df\n",
        "dd['valid'] = valid_image_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ADnofbeBP5n",
        "outputId": "e0ec1a4d-f9d3-4e5f-b20e-adeea18fedba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1272it [00:00, 11599.50it/s]\n"
          ]
        }
      ],
      "source": [
        "train_image_labels = getImageLabels(train_image_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj-b8MvuBTKN",
        "outputId": "249bb7a7-603f-446b-e240-550ba139e382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1272it [00:05, 254.08it/s]\n"
          ]
        }
      ],
      "source": [
        "train_images = getImage(train_image_df, size = 224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdvqpNdPBWjV",
        "outputId": "2fd52d90-08ed-429c-d4f4-78d6b35926bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1272, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ztS4uYVZBaAa"
      },
      "outputs": [],
      "source": [
        "train_datagen.fit(train_images,augment=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PYAmPZ3kBfKZ"
      },
      "outputs": [],
      "source": [
        "train_generator = train_datagen.flow(\n",
        "    x=train_images,\n",
        "    y=train_image_labels,\n",
        "    batch_size = 32\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOVO8rP7Bj2Z",
        "outputId": "c1ef189a-2681-498d-b929-c0d945ccef03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "288it [00:00, 12416.58it/s]\n"
          ]
        }
      ],
      "source": [
        "valid_image_labels = getImageLabels(valid_image_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS6wcJRpBpqm",
        "outputId": "6554d77e-a3ae-462c-caf4-c5ef5ea6b0f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "288it [00:01, 223.29it/s]\n"
          ]
        }
      ],
      "source": [
        "valid_images = getImage(valid_image_df, size = 224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "g6ra0b7ZBtxN"
      },
      "outputs": [],
      "source": [
        "test_datagen.fit(valid_images,augment=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "sZmufgppBxqQ"
      },
      "outputs": [],
      "source": [
        "validation_generator = test_datagen.flow(\n",
        "    x=valid_images,\n",
        "    y=valid_image_labels,\n",
        "    batch_size = 1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G79_WD5TB1v0",
        "outputId": "ced00616-17fb-4531-d154-18cac5229ba4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39\n"
          ]
        }
      ],
      "source": [
        "###################\n",
        "# Construct model #\n",
        "###################\n",
        "\n",
        "\n",
        "\n",
        "#model parameters for training\n",
        "#K.set_learning_phase(1)\n",
        "nb_train_samples = len(train_images)\n",
        "nb_validation_samples = len(valid_images)\n",
        "epochs = 12\n",
        "batch_size = 32\n",
        "steps_per_epoch = nb_train_samples//batch_size\n",
        "print(steps_per_epoch)\n",
        "n_classes = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_RjjRn2B5qB",
        "outputId": "4b81b6ba-ad68-4271-cf6c-d023d619052e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "51879936/51877672 [==============================] - 0s 0us/step\n",
            "51888128/51877672 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "#Building a model\n",
        "input_shape = (224, 224, 1)\n",
        "#model = densenet(input_shape, n_classes)\n",
        "model = build_model()\n",
        "# Build optimizer\n",
        "#opt = keras.optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=0.1)\n",
        "#opt = RAdam(total_steps=5000, warmup_proportion=0.1, min_lr=1e-4,name='RAdam')\n",
        "\n",
        "\n",
        "model.compile(loss=BinaryFocalLoss(gamma = 2), optimizer='adam', metrics=['acc', 'mse'])\n",
        "#model.compile(loss=BinaryFocalLoss(gamma = 2), optimizer=opt, metrics=['acc', 'mse'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "OZMvsQrwB_Ko"
      },
      "outputs": [],
      "source": [
        "#callbacks for early stopping incase of reduced learning rate, loss unimprovement\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=8, verbose=1, min_delta=1e-4)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, verbose=1, min_lr=0.0001)\n",
        "callbacks_list = [early_stop, reduce_lr]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TEyFNbdCCWl",
        "outputId": "f3402e67-59c1-417a-9cf9-39cacae7431a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "39/39 [==============================] - 100s 2s/step - loss: 0.2425 - acc: 0.5661 - mse: 0.2487 - val_loss: 1.5245 - val_acc: 0.7778 - val_mse: 0.2227 - lr: 0.0010\n",
            "Epoch 2/12\n",
            "39/39 [==============================] - 49s 1s/step - loss: 0.1493 - acc: 0.7105 - mse: 0.2119 - val_loss: 0.2201 - val_acc: 0.5556 - val_mse: 0.2421 - lr: 0.0010\n",
            "Epoch 3/12\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.1379 - acc: 0.7452 - mse: 0.1940\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "39/39 [==============================] - 52s 1s/step - loss: 0.1379 - acc: 0.7452 - mse: 0.1940 - val_loss: 0.5625 - val_acc: 0.7778 - val_mse: 0.1763 - lr: 0.0010\n",
            "Epoch 4/12\n",
            "39/39 [==============================] - 49s 1s/step - loss: 0.1332 - acc: 0.7476 - mse: 0.1940 - val_loss: 0.1396 - val_acc: 0.6667 - val_mse: 0.1441 - lr: 1.0000e-04\n",
            "Epoch 5/12\n",
            "39/39 [==============================] - 49s 1s/step - loss: 0.1204 - acc: 0.7976 - mse: 0.1781 - val_loss: 0.1325 - val_acc: 0.7778 - val_mse: 0.1854 - lr: 1.0000e-04\n",
            "Epoch 6/12\n",
            "39/39 [==============================] - 48s 1s/step - loss: 0.1122 - acc: 0.8145 - mse: 0.1690 - val_loss: 0.0479 - val_acc: 1.0000 - val_mse: 0.1072 - lr: 1.0000e-04\n",
            "Epoch 7/12\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.1048 - acc: 0.8323 - mse: 0.1571\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "39/39 [==============================] - 51s 1s/step - loss: 0.1048 - acc: 0.8323 - mse: 0.1571 - val_loss: 0.2474 - val_acc: 0.5556 - val_mse: 0.2368 - lr: 1.0000e-04\n",
            "Epoch 8/12\n",
            "39/39 [==============================] - 51s 1s/step - loss: 0.1049 - acc: 0.8331 - mse: 0.1558 - val_loss: 0.0799 - val_acc: 0.8889 - val_mse: 0.1475 - lr: 1.0000e-04\n",
            "Epoch 9/12\n",
            "39/39 [==============================] - 49s 1s/step - loss: 0.0978 - acc: 0.8452 - mse: 0.1459 - val_loss: 0.1107 - val_acc: 0.6667 - val_mse: 0.1719 - lr: 1.0000e-04\n",
            "Epoch 10/12\n",
            "39/39 [==============================] - 49s 1s/step - loss: 0.0967 - acc: 0.8282 - mse: 0.1444 - val_loss: 0.1642 - val_acc: 0.6667 - val_mse: 0.1761 - lr: 1.0000e-04\n",
            "Epoch 11/12\n",
            "39/39 [==============================] - 51s 1s/step - loss: 0.0954 - acc: 0.8444 - mse: 0.1441 - val_loss: 0.0614 - val_acc: 0.8889 - val_mse: 0.1084 - lr: 1.0000e-04\n",
            "Epoch 12/12\n",
            "39/39 [==============================] - 49s 1s/step - loss: 0.0937 - acc: 0.8435 - mse: 0.1387 - val_loss: 0.0695 - val_acc: 0.8889 - val_mse: 0.1246 - lr: 1.0000e-04\n"
          ]
        }
      ],
      "source": [
        "#train the module\n",
        "model_history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    workers=0,\n",
        "    use_multiprocessing=False,  \n",
        "    steps_per_epoch = nb_train_samples//batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples //batch_size,\n",
        "    callbacks=callbacks_list\n",
        "    \n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Bone Fracture Detection V3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}